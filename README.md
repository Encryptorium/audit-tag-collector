# Audit Tag Collector

## Overview

The **Audit Tag Collector** is a Python script designed to scan a code repository for audit-related annotations. It identifies specific tags (e.g., `// @audit`, `// @audit-question`) and generates two types of reports:

1. **JSON Report** (`audit_tag_report.json`): A comprehensive report containing all extracted annotations.
2. **Markdown Report** (`audit_tag_report.md`): A well-organized report with categorized annotations, including an "Outstanding Questions" section at the top.

The script is ideal for developers and auditors who need to keep track of code reviews, security concerns, and questions that arise during the development process.

## Features

- **Automated Scanning**: The script automatically traverses the specified repository and scans files with specific extensions for audit annotations.
- **Categorized Reporting**: The Markdown report categorizes annotations for easy review, with questions and outstanding issues highlighted.
- **Contextual Information**: The report includes a configurable number of lines before and after each annotation to provide context.
- **Self-Ignoring**: The script automatically ignores itself during the scan, ensuring that it doesn't accidentally include its own annotations in the report.

## Usage

To use the script, follow these steps:

### 1. Prerequisites

Ensure you have Python installed on your system. The script is compatible with Python 3.x.

### 2. Clone or Download the Repository

Clone the repository containing the `audit-tag-collector.py` script or download it directly.

### 3. Run the Script

Navigate to the directory containing the `audit-tag-collector.py` script and run it using the following command:

```
python audit-tag-collector.py /path/to/repo
```

Replace `/path/to/repo` with the actual path to the repository you want to scan.

### 4. View the Reports

After running the script, two reports will be generated in the same directory as the script:

- **`audit_tag_report.json`**: A JSON file containing all extracted annotations.
- **`audit_tag_report.md`**: A Markdown file organized by categories, with "Outstanding Questions" at the top.

## Configuration

The script includes several configuration options that can be adjusted to suit your needs. These options are set at the beginning of the script:

- **CONTEXT_LINES_BEFORE**: Defines how many lines before the annotation should be included in the context (default: 2).
- **CONTEXT_LINES_AFTER**: Defines how many lines after the annotation should be included in the context (default: 2).
- **OUTPUT_JSON_FILE**: The name of the JSON output file (default: `audit_tag_report.json`).
- **OUTPUT_MD_FILE**: The name of the Markdown output file (default: `audit_tag_report.md`).
- **DATE_FORMAT**: Specifies the format for the date in the report header (default: `"%B %d, %Y, %H:%M:%S"`).

## Supported Annotations

The script recognizes the following annotations in the code:

- **`// @audit`**: General audit tag to highlight sections of code that require special attention.
- **`// @audit-question`**: Marks a question or concern that needs to be addressed.
- **`// @audit-ok`**: Indicates that a section of code has been reviewed and deemed secure.
- **`// @audit-info`**: Provides additional information useful for the auditor or reviewer.
- **`// @audit-issue`**: Highlights known issues or potential vulnerabilities in the code.
- **`// @audit-gas`**: Indicates areas of the code that may have significant gas usage implications (relevant for blockchain applications).
- **`// @audit-noncritical`**: Marks non-critical issues that could impact performance or usability.
- **`// @audit-warning`**: Warns of potential risks that are not critical but should be monitored.
- **`// @audit-todo`**: Indicates parts of the code that are incomplete or need further work.
- **`// @audit-clarify`**: Requests clarification on specific code logic or implementation details.
- **`// @audit-test`**: Highlights newly created tests that should be reviewed.

## Example Output

To see an example of the kind of Markdown report generated by this script, refer to the [example_audit_tag_report.md](example_audit_tag_report.md) file included in this repository.

This example report provides a detailed look at how annotations are categorized, how context is provided for each annotation, and how outstanding questions are highlighted at the top of the report.

## Implementation Details

### How It Works

1. **Scanning Files**: The script recursively scans the specified repository, looking for files with specific extensions (`.sol`, `.js`), and extracts lines containing predefined audit annotations.
   
2. **Context Extraction**: For each annotation found, the script extracts a few lines before and after the annotation to provide context.

3. **Report Generation**: The script generates a JSON report with all extracted annotations and a Markdown report organized by categories, with outstanding questions highlighted at the top.

### Ignoring Itself

The script is designed to ignore itself during the scan, ensuring that it does not accidentally include its own annotations in the generated reports. This is achieved by excluding the script's filename when processing files.

## Contributing

If you have suggestions for improvements or encounter any issues, feel free to open an issue or submit a pull request on the repository.

## License

This project is open-source and available under the MIT License.